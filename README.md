# ğŸ§  LLM Fine-tuning & vLLM Serving (Docker + Configurable)

ì´ ë ˆí¬ëŠ” **ì„¤ì • ê¸°ë°˜(Config-driven)**ìœ¼ë¡œ ë””ìì¸ëœ LLM íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.
ë³µì¡í•œ ì½”ë“œ ìˆ˜ì • ì—†ì´ **YAML íŒŒì¼**ê³¼ **.env** íŒŒì¼ë§Œìœ¼ë¡œ í•™ìŠµê³¼ ì„œë¹™ ì„¤ì •ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ë³€ê²½ ì‚¬í•­ (2026 Updated)
- **âš¡ Scripts**: ë³µì¡í•œ docker ëª…ë ¹ì–´ë¥¼ ê¸°ì–µí•  í•„ìš” ì—†ì´ `scripts/` í´ë”ì˜ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰
- **âš™ï¸ Configs**: `configs/train.yaml`ì—ì„œ í•™ìŠµ íŒŒë¼ë¯¸í„° ì œì–´
- **ğŸŒ Env**: `.env` íŒŒì¼ë¡œ ê²½ë¡œ ë° í¬íŠ¸ ì„¤ì • ê´€ë¦¬

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°
```
llm_env/
â”œâ”€â”€ configs/             # âš™ï¸ [NEW] í•™ìŠµ ì„¤ì • (YAML)
â”‚   â””â”€â”€ train.yaml
â”œâ”€â”€ scripts/             # âš¡ [NEW] ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (build, train, serve)
â”œâ”€â”€ docker/              # Dockerfile ëª¨ìŒ
â”œâ”€â”€ .env                 # ğŸŒ [NEW] í™˜ê²½ ë³€ìˆ˜ (ê²½ë¡œ, í¬íŠ¸ ë“±)
â”œâ”€â”€ docker-compose.yml   # í†µí•©ëœ docker-compose
â””â”€â”€ README.md
```

## 1ï¸âƒ£ ì‚¬ì „ ì¤€ë¹„
1. **.env ìƒì„±**
   ```bash
   cp .env.example .env
   # .env íŒŒì¼ì„ ì—´ì–´ì„œ ê²½ë¡œ(HF_CACHE_DIR ë“±)ë¥¼ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”!
   ```

2. **ë² ì´ìŠ¤ ì´ë¯¸ì§€ ë¹Œë“œ (ìµœì´ˆ 1íšŒ)**
     ì´ ì‘ì—…ì€ ì‹œê°„ì´ ê½¤ ê±¸ë¦½ë‹ˆë‹¤ (Pytorch, CUDA ë“± ì„¤ì¹˜).
   - **Windows**: `.\scripts\build_base.ps1`
   - **Linux/WSL**: `./scripts/build_base.sh`

## 2ï¸âƒ£ í•™ìŠµ (Train)
`configs/train.yaml` íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ì›í•˜ëŠ” ëª¨ë¸ê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•œ í›„ ì‹¤í–‰í•©ë‹ˆë‹¤.

- **Windows**: `.\scripts\run_train.ps1`
- **Linux/WSL**: `./scripts/run_train.sh`

í•™ìŠµì´ ì™„ë£Œë˜ë©´ `models/` í´ë”ì— LoRA ì–´ëŒ‘í„°ê°€ ì €ì¥ë©ë‹ˆë‹¤.

## 3ï¸âƒ£ ì„œë¹™ (Serve)
vLLM ì—”ì§„ê³¼ API ì„œë²„ë¥¼ ë™ì‹œì— ì‹¤í–‰í•©ë‹ˆë‹¤.

- **Windows**: `.\scripts\run_serve.ps1`
- **Linux/WSL**: `./scripts/run_serve.sh`

### API í…ŒìŠ¤íŠ¸
```bash
curl http://localhost:9000/chat?q="Hello! Who are you?"
```

## ğŸ› ï¸ ê³ ê¸‰ ì„¤ì •
### `configs/train.yaml`
```yaml
model:
  name: "unsloth/mistral-7b-v0.3"
  load_in_4bit: true
  chat_template: |
    {% for message in messages %}
    ...
    {% endfor %}

lora:
  r: 16
  lora_alpha: 16
```

### `.env`
```bash
VLLM_PORT=8000
API_PORT=9000
MODEL_NAME=my_model
```
